# Arabic Visual Question Answering
Visual Question Answering (VQA) is a system that
generates an answer based on considering multiple dissimilar tasks
related to both visual and textual interpretation of a question and
an image all inside a single cohesive framework. VQA provides
opportunities to better interpretation visual features in many domains.
In this project, two visual question answering models that answer
an Arabic question given an image was implemented, and compared
against a baseline model. Experiments performed on the VQA dataset,
which is a benchmark dataset for visual question answering, show that
the models implemented result in a better accuracy in comparison to
the baseline model and subset of previous works towards the same
problem.

<p align="center">
<img width="806" alt="Screenshot 2022-07-25 040121" src="https://user-images.githubusercontent.com/47125583/180674380-1328fd7a-36f6-4bfb-bda7-0e053b78cea3.png">
</p>
